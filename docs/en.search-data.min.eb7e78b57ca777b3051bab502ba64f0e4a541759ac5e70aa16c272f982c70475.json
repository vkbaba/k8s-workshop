[{"id":0,"href":"/k8s-workshop/docs/container/appendix/image-details/","title":"イメージの詳細","section":"コンテナハンズオン","content":"イメージの詳細 #  "},{"id":1,"href":"/k8s-workshop/docs/container/","title":"コンテナハンズオン","section":"Docs","content":"ハンズオンの概要 #  コンテナは、OSレベルの仮想化の軽量な形態です。これにより、完全なOSを実行することなく、一連のアプリケーションプロセスを独自の分離された環境で実行することができます。\nこのハンズオンでは、コンテナイメージを構築して実行する方法の基本を学びます。使用するツールはdockerです。\n使用するラボ #   "},{"id":2,"href":"/k8s-workshop/docs/container/basic/","title":"基本操作","section":"コンテナハンズオン","content":"コンテナの起動 #  dockerを使ってアプリケーションをコンテナ内で起動するには、コンテナイメージが必要です。コンテナイメージは、アプリケーションを配布するためのパッケージメカニズムとして機能し、アプリケーションソフトウェア、オペレーティングシステムファイル、ライブラリ、その他アプリケーションの実行に必要なソフトウェアが含まれています。\n アプリケーション用のあらかじめ構築されたコンテナイメージや、独自のコンテナイメージを構築するためのベースとなるコンテナイメージは、イメージレジストリを使用して配布されます。\nイメージレジストリは、Docker Hub\r のようなホスト型サービスが存在します。また、Github\r やGitLab\rのようなGitリポジトリのホスティングサービスでも、コンテナイメージのホスティングと配布をサポートしています。\ndocker runを使ってイメージレジストリから既存のコンテナイメージをプルダウンして実行するには以下を実行します。\ndocker run docker.io/busybox:latest date アウトプットは以下のようになります。\nUnable to find image 'busybox:latest' locally latest: Pulling from library/busybox e2334dd9fee4: Pull complete Digest: sha256:a8cf7ff6367c2afa2a90acd081b484cbded349a7076e7bdf37a05279f276bc12 Status: Downloaded newer image for busybox:latest Mon Apr 20 00:11:37 UTC 2020  このコマンドは、イメージをローカル環境にプルダウンするために行われた手順の詳細をログに記録します。この処理が完了すると、コンテナイメージからコンテナが起動され、コマンドラインで指定されたdateコマンドがコンテナ内で実行されます。dateコマンドはすぐに終了するので、コンテナはそのままシャットダウンされます。\n今回使用したコンテナイメージは、busyboxというものです。これは、非常にミニマルなUnixライクのコンテナイメージで、よく利用されるコマンドを詰め込んでいる便利なイメージです。最新バージョンのコンテナイメージを使用し（:latest）、Docker Hubのイメージレジストリ（docker.io）から取得するように指定しました。\nこのコマンドをもう1回実行してみてください。\ndocker run docker.io/busybox:latest date dateコマンドがすぐに実行され、コンテナイメージを最初にプルダウンする必要があるという詳細情報は記録されないことがわかります。これは、コンテナイメージがローカル環境にキャッシュされ、次回以降の実行時に使用されるからです。\nどのようなコンテナイメージがローカル環境にプルダウンされたかは、次のように実行することで確認できます。\ndocker images アウトプットは以下のようになります。\nREPOSITORY TAG IMAGE ID CREATED SIZE busybox latest be5888e67be6 5 days ago 1.22MB  必要であれば、docker runはコンテナイメージを最初に必要とされるときにプルダウンします。実行される前にイメージをプルダウンしたい場合は、docker pullコマンドを使用することができます。\ndocker pull docker.io/busybox:latest ターミナルの操作 #  先ほどはbusybox コンテナイメージから起動したコンテナ内で date コマンドを実行しました。コンテナイメージに含まれている任意のアプリケーションを実行することができます。\nコンテナを作成して、その中でコマンドを実行するために対話したい場合は、対話型シェルを実行します。\ndocker run -it busybox sh 対話型端末を必要とするコマンドを実行する場合は、docker runに-itオプションを指定する必要があります。これにより、ターミナルが確保され、stdinが入力可能な状態に保たれます。\n参考 : https://ohbarye.hatenablog.jp/entry/2019/05/05/learn-tty-with-docker\r\n「コンテナの中に入って何か操作をしたい場合 = -it」 と最初は覚えてしまいましょう。  また、今回はコンテナイメージの名前をbusyboxと略しています。バージョンタグが指定されていない場合は latest が使用されます。イメージレジストリのホストが指定されていない場合は、dockerのグローバル設定で定義されているデフォルトのイメージレジストリが検索されます。すでにDocker Hubからbusybox:latestのイメージを取り出しているので、それがマッチします。\nコンテナ内で実行されているプロセスの一覧を見るには、次のように実行します。\nps 以下のような出力が表示されるはずです。\npid user time command 1 root 0:00 sh 8 root 0:00 ps  コンテナのコンテキスト内で起動したプロセスのみが表示されます。下層のコンテナホスト（例えばコンテナを実行している仮想マシン）で実行されているプロセスは表示されません。\n実行中のコンテナの一覧を表示するには、コンテナホスト上で実行します。ターミナル2 でdocker ps コマンドを試してみてください（ターミナル1 はコンテナの中に入ったままです）。\nexit docker ps 上記で起動したコンテナが対話型シェルで実行されているのが確認できるはずです。\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ae576793e3e9 busybox \u0026quot;sh\u0026quot; 32 seconds ago Up 31 seconds recursing_leavitt  コンテナホストから既存のコンテナにアクセスし、その中でコマンドを実行するには、docker execコマンドを使用します。docker runと同様に、インタラクティブなターミナルを必要とするコマンドを実行する場合は、-itオプションを使用します。\ndocker execを実行する際には、アクセスしたいコンテナのIDを指定する必要があります。最後に起動したコンテナのコンテナIDを表示するには、次のコマンドを実行します。\ndocker ps -ql では、起動中のコンテナの中にexec コマンドで入ってみましょう。\ndocker exec -it `docker ps -ql` sh 再度 ps を実行します。\nps これで、2つのシェルプロセスが実行されていることが確認できます。\n1つ目の対話型ターミナルで次のように実行して終了します。\nexit このプロセスはコンテナ内で実行されているメインプロセスであり、プロセスIDは1であるため、コンテナがシャットダウンされ、2つ目の対話型端末のセッションも閉じられます。\nコンテナの停止 #  コンテナがシャットダウンされると、アプリケーションプロセスはなくなりますが、コンテナの状態のコピーは保持されます。停止したコンテナを含むすべてのコンテナの一覧は、次のように実行することで確認できます。\ndocker ps -a いくつものコンテナを起動しているので、停止しているコンテナが複数表示されているはずです。\nONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ae576793e3e9 busybox \u0026quot;sh\u0026quot; About a minute ago Exited (0) 16 seconds ago recursing_leavitt e894e7d5790f busybox:latest \u0026quot;date\u0026quot; 3 minutes ago Exited (0) 3 minutes ago heuristic_bassi 9d1706a4b51f busybox:latest \u0026quot;date\u0026quot; 3 minutes ago Exited (0) 3 minutes ago inspiring_banzai  コンテナからの出力はログファイルにも取り込まれます。コンテナIDを引数にしてdocker logsコマンドを実行すると、実行中または停止中のコンテナのログファイルを見ることができます。\ndocker logs `docker ps -ql` コンテナのログファイルに加えて、コンテナ内からファイルシステムに加えられた変更のコピーも保存されるため、停止中のコンテナからファイルをコピーしたり、停止中のコンテナから新しいコンテナイメージを作成したりすることもできます。 補足 どこにあるか   停止したコンテナにはいくつかの用途がありますが、スペースを消費しますので、停止したコンテナを削除することが重要です。そうしないと、最終的にはディスクスペースが足りなくなってしまいます。\n停止したコンテナを1つだけ削除するには、コンテナIDを引数にしてdocker rmを使用します。\ndocker rm `docker ps -ql` これで、停止していた2つのコンテナだけが残るはずです。\ndocker ps -a 停止しているコンテナをすべて削除するには、次のように実行します。\ndocker rm $(docker ps -aq) docker ps -aは停止中のコンテナだけでなく、稼働中のコンテナも反応しますが、docker rmコマンドは停止中のコンテナのみを削除します。\nこれでコンテナは残っていないはずです。\n停止したコンテナをシャットダウンした後に操作する必要がないことがわかっている場合は、docker runの実行時に--rmオプションを使用できます。\ndocker run --rm busybox date このオプションを使用すると、停止したコンテナは自動的に削除されます。 検証目的においては常に--rm オプションをつけるよう意識しておくとディスクスペースの節約につながります。\n "},{"id":3,"href":"/k8s-workshop/docs/kubernetes/basic/","title":"基本操作","section":"Kubernetes ハンズオン","content":"クラスタへのアクセス #  これから行うハンズオンでは、kubectl CLIを使用してKubernetesとやり取りします。このCLI は、ワークショップ環境の「ターミナル」タブからアクセスできるインタラクティブなターミナルセッションで提供されます。ご自身のコンピュータに何かをインストールする必要はありません。ここでは、Webブラウザを使ってすべての操作を行うことになります。使用するKubernetesクラスタにはすでに接続されているので、ログインする必要はありません。\nワークショップ環境では、KubernetesクラスタをWebベースで確認することもできます。これは、ワークショップ環境の「コンソール」タブから利用できます。これは、ハンズオンで行うことの結果を視覚的に確認するために含まれていますが、ハンズオンはこれに依存しません。\nハンズオンを続ける前に、kubectlコマンドが実行され、ワークショップ環境も機能していることを確認します。これを行うには、次のように実行します。\nkubectl version 実行すると、次のような出力が表示されます。\nClient Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;17\u0026quot;, GitVersion:\u0026quot;v1.17.0\u0026quot;, GitCommit:\u0026quot;70132b0f130acc0bed193d9\rba59dd186f0e634cf\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2019-12-07T21:20:10Z\u0026quot;, GoVersion:\u0026quot;go1.13.4\u0026quot;, Compiler:\u0026quot;\rgc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;}\rServer Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;17\u0026quot;, GitVersion:\u0026quot;v1.17.0\u0026quot;, GitCommit:\u0026quot;70132b0f130acc0bed193d9\rba59dd186f0e634cf\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2019-12-07T21:12:17Z\u0026quot;, GoVersion:\u0026quot;go1.13.4\u0026quot;, Compiler:\u0026quot;\rgc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;}\r 使用しているKubernetesのバージョンは、ここで示したバージョンと異なる場合があります。\nアプリケーションのデプロイ #  さて、Kubernetesクラスタへのアクセスが正常に行われていることを確認したら、早速、ブログサイトを実装したフロントエンドのWebアプリケーションと、ブログ記事を保存するためのPostgreSQLデータベースで構成される完全なアプリケーションをデプロイしてみましょう。\nこれは、すでに構成ができていれば、Kubernetesに完全なアプリケーションをいかに早くデプロイできるかを示すためです。アプリケーション全体がデプロイされたら、フロントエンドのWebアプリケーションコンポーネントを削除し、段階的にデプロイし直すことで、どのように組み合わされているのか、どのようにKubernetesを使用しているのかを確認することができます。\nデプロイしたいアプリケーションの最初の部分は、PostgreSQLデータベースです。これをデプロイするためのリソースファイル一式は、databaseディレクトリにあります。\nls -las database/ このディレクトリ内の各ファイルには、アプリケーションコンポーネントの配置を構成するための異なるリソース定義が含まれています。\n各ファイルの定義を調べるよりも、まずはディレクトリ内のリソースをKubernetes に処理させてみましょう。これを行うには、次のように実行します。\nkubectl apply -f database/ --dry-run これで出力されるはずです。\nsecret/blog-credentials created (dry run)\rservice/blog-db created (dry run)\rpersistentvolumeclaim/blog-database created (dry run)\rdeployment.apps/blog-db created (dry run)\r 今回のkubectl applyコマンドは、設定ファイルやディレクトリに含まれるファイル群からリソースを作成するためのものです。ここでは\u0026ndash;dry-runオプションを使い、クラスタ内のオブジェクトを一切作成せずに、どのようなオブジェクトを作成するかを指示しています。また、\u0026ndash;dry-runオプションはリソースの定義を検証し、エラーがある場合は警告します。\nあるコマンドが何をするのか、どんなオプションを受け付けるのかが不明な場合は、\u0026ndash;helpオプションを付けて実行することができます。\nkubectl apply --help ドライランデプロイメントを行うことで、作成されるリソースを確認することができました。実際にデータベースコンポーネントをデプロイするために、今度は次のように実行します。\nkubectl apply -f database/ ドライランの時と同様に、kubectl applyはリソースをリストアップしますが、今回は実際にリソースが作成されます。\nsecret/blog-credentials created\rservice/blog-db created\rpersistentvolumeclaim/blog-database created\rdeployment.apps/blog-db created\r このリストの中で重要なリソースはdeployment です。deployment では、アプリケーションにデプロイするコンテナイメージの名前、起動するインスタンスの数、デプロイメントの管理方法などを指定します。\nデプロイの進捗を監視し、完了を知るには、次のコマンドを実行します。\nkubectl rollout status deployment/blog-db 引数には、リソースのタイプとこのインスタンスの名前を含む、リソースのフルネームを指定します。この場合、インスタンスはblog-dbという名前でした。\nデータベースがデプロイされたので、今度はフロントエンドのWebアプリケーションを次のように実行してデプロイします。\nkubectl apply -f frontend/ 出力は以下のようになるはずです。\npersistentvolumeclaim/blog-media created\rdeployment.apps/blog created\rservice/blog created\ringress.extensions/blog created\r 以下を実行して監視し、デプロイが完了するのを待ちます。\nkubectl rollout status deployment/blog デプロイしたアプリケーションへのアクセス #  フロントエンドのWebアプリケーション用にingressオブジェクトが作成されていることに注目してください。このオブジェクトは、アクセス可能なURLを払い出し、Webアプリケーションへのアクセスを設定します。\nこの例では、WebアプリケーションにアクセスするためのURLは次のようになります。ターミナルではなく、ブラウザの別タブから払い出されたURL にアクセスしてください。\nNS=$(kubectl config view -o jsonpath=\u0026#39;{.contexts[].context.namespace}\u0026#39;) echo $NS http://blog-${NS}.tdc-reg-prod-d66138e.tanzu-labs.esp.vmware.com 1つ目のコマンドはこの環境で払い出されるURL 名の一部（名前空間）を取得しています。URL 中の${NS} は取得した名前空間で置き換えてください。例えば下記のようになります。\nhttp://blog-eduk8s-labs-w01-s287.tdc-reg-prod-d66138e.tanzu-labs.esp.vmware.com\r\n この時点では 500 Internal Server Error が表示されることに注意してください。  このリンクをクリックして、フロントエンドのWebアプリケーションにアクセスします。利用できないと表示された場合は、利用できるようになるまでページを更新してください。これは、Ingress の設定に時間がかかる場合があるためです。\nまだ、ブログ記事は表示されません。データベースの設定と入力については後ほど説明します。\nKubernetesクラスタのWebコンソールを使用すると、どのリソースが作成されているか、またそれらのリソース間の関係をブラウザで視覚的に表示することができますが、ほとんどの開発者はkubectlを使用してコマンドラインからKubernetesクラスタを操作します。\n現在の名前空間にある、すでに作成されたすべてのデプロイメントの一覧を表示するには、次のように実行します。\nkubectl get deployment 出力は以下のようになるはずです。\nNAME READY UP-TO-DATE AVAILABLE AGE\rblog 2/2 2 2 5m\rblog-db 1/1 1 1 5m\r 特定のリソースに絞り込みたい場合は、コマンドにそのリソース名を加えることができます。\nkubectl get deployment/blog これで、1つのリソースだけの出力が得られるはずです。もしくは、以下のように実行することもできます。\nkubectl get deployment blog 出力の最初の部分は以下のようになるはずです。\nName: blog\rNamespace: lab-k8s-fundamentals-user1\rCreationTimestamp: Tue, 04 Feb 2020 03:06:56 +0000\rLabels: app=blog\rAnnotations: deployment.kubernetes.io/revision: 1\rSelector: app=blog\rReplicas: 2 desired | 2 updated | 2 total | 2 available | 0 unavailable\rStrategyType: RollingUpdate\rMinReadySeconds: 0\rRollingUpdateStrategy: 25% max unavailable, 25% max surge\rPod Template:\r....\r これは比較的読みやすい形式にしたものであり、生のリソース定義を見るには、kubectl getの-o yaml表示出力オプションを使います。\nkubectl get deployment/blog -o yaml また、YAMLではなくJSONで作業をしたい場合には以下を実行します。\nkubectl get deployment/blog -o json "},{"id":4,"href":"/k8s-workshop/docs/kubernetes/","title":"Kubernetes ハンズオン","section":"Docs","content":"ハンズオン概要 #  KubernetesのWebサイトでは、Kubernetesを次のように説明しています。\n コンテナ化されたアプリケーションのデプロイ、スケーリング、管理を自動化するためのオープンソースのシステムです。\n このワークショップでは、Kubernetesの使い方を簡単に体験していただくことを目的としています。その過程で、Kubernetesにアプリケーションをデプロイする際の基本的なコンセプトについて学びます。このワークショップでは、開発者がKubernetesを使用するために必要な知識に焦点を当てます。これは、Kubernetesプラットフォームの運用方法に関するワークショップではありません。\n使用するラボ #  "},{"id":5,"href":"/k8s-workshop/docs/container/network/","title":"Web サーバーの公開","section":"コンテナハンズオン","content":"ネットワークサービス #  これまでに実行したすべてのコンテナは、実行元のターミナルに接続されたままでした。コンテナからの出力はターミナルに表示され、コンテナを停止したときに初めてコマンドプロンプトが戻ってきます。\nコンテナ内で実行される長時間稼働のネットワークサービスは、ターミナルから切り離してバックグラウンドプロセスとして実行する必要があります。\nbusyboxイメージを使用してWebサーバーを実行するには、次のように実行します。\ndocker run --rm -d --name httpd -p 8080:80 busybox httpd -f -vv docker runに-dオプションを付けると、コンテナがターミナルから切り離されてバックグラウンドで実行されます。\nこのコンテナをより簡単に識別して操作できるように、\u0026ndash;nameオプションを使ってhttpdという名前をつけます。\nWebサーバはネットワークサービスなので、公開するネットワークポートを指定する必要があります。これには-pオプションを使用します。\n最後に、コンテナ内で実行するコマンドとして、httpd -f -vvを使用します。\nhttpdの-fオプションは、ウェブサーバがコンテナのコンテキスト内でフォアグラウンドプロセスとして実行されるようにします。これが行われないと、コンテナはすぐに終了してしまいます。vv は詳細なロギングを可能にします。\nコンテナが稼働していることを確認するには、次のように実行します。\ndocker ps コンテナからの出力を尾行するには、次のように実行します。\ndocker logs -f httpd コンテナIDの代わりに、コンテナに割り当てたhttpd名を使用します。f オプションは、ログファイルを継続的にテーリングすることを意味します。\n初期状態ではログが出力されていませんが、次のように実行して、Webサーバに対してWebリクエストを行ってください。\ncurl localhost:8080 を実行すると、リクエストの詳細がログに記録されるはずです。\nこのケースでは、提供すべきファイルを提供していないため、Webサーバからエラーが発生しています。\nコンテナがターミナルから切り離されたので、コンテナを停止するには以下を実行する必要があります。\ndocker stop --time 2 httpd 演習 #  busybox ではなくnginx イメージを使って、コンテナでWeb サーバーをバックグラウンドで実行してみてください。また、curl で接続して、応答が返ってくることを確認しましょう。次に、nginx のログを出力してみて、実際にアクセスがあったことを確かめてみてください。最後に、実行したコンテナを停止し、削除をしてください。\n解答 初めてnginx を実行する際はイメージキャッシュが保存されていないため、自動的にレジストリからダウンロードされます。\ndocker run --rm -d --name nginx -p 8080:80 nginx 割り当てたポートに対してcurl を実行してみましょう。\ncurl localhost:8080 以下のように、\u0026ldquo;Welcome to nginx!\u0026rdquo; と表示されたらOK です。\n[~/exercises] $ curl localhost:8080 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; html { color-scheme: light dark; } body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; アクセスログも見てみましょう。\ndocker logs -f nginx 自身のIP アドレス（ここでは172.17.0.1）からHTTP GET リクエストが実行されていることが分かりますね。\n172.17.0.1 - - [17/Nov/2021:12:17:15 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 200 615 \u0026#34;-\u0026#34; \u0026#34;curl/7.66.0\u0026#34; \u0026#34;-\u0026#34; 最後にコンテナを削除します。起動時に\u0026ndash;rm オプションを付けたので、docker stop で自動的に削除されます。\ndocker stop nginx    "},{"id":6,"href":"/k8s-workshop/docs/kubernetes/resource/","title":"リソースの詳細","section":"Kubernetes ハンズオン","content":"Deployment, Replicaset, #  前の手順でDeployment を作成しましたが、Deployment は追加のリソースを作成します。調べてみましょう。\nkubectl get all -o name -l app=blog all はリソース名ではなく、Kubernetesのコアのリソースタイプを表示するエイリアスです。\n出力は以下のようになるはずです。\npod/blog-6b8999855c-6jjhj pod/blog-6b8999855c-zk8pg deployment.apps/blog replicaset.apps/blog-6b8999855c Deployment を作成しただけなのに、結果的にReplicaset とPod のリソースが追加で作成されています。\nこれは、Deploymentが、Replicaset を作成するためのテンプレートとして機能するためです。また、Replicaset は、Pod を作成するためのテンプレートとして機能します。Pod は、アプリケーションのインスタンスを表すものです。このケースでは、レプリカの数が2に設定されているため、2つのPod が存在します。\nReplicaset のリソース定義を表示するには、次のように実行します。\nkubectl get replicaset -l app=blog -o yaml spec:\rreplicas: 2\rselector:\rmatchLabels:\rapp: blog\rpod-template-hash: \u0026quot;896156207\u0026quot;\rtemplate:\rmetadata:\rcreationTimestamp: null\rlabels:\rapp: blog\rpod-template-hash: \u0026quot;896156207\u0026quot;\rspec:\rcontainers:\r- env:\r- name: BLOG_SITE_NAME\rvalue: EduK8S Blog\rimage: quay.io/eduk8s-labs/app-k8s-fundamentals-frontend:latest\rimagePullPolicy: Always\rname: blog\rports:\r- containerPort: 8080\rprotocol: TCP\rresources: {}\rterminationMessagePath: /dev/termination-log\rterminationMessagePolicy: File\rdnsPolicy: ClusterFirst\rrestartPolicy: Always\rschedulerName: default-scheduler\rsecurityContext: {}\rterminationGracePeriodSeconds: 30\r すなわち、Replicase のマニフェストは、Deployment のSpec で提供されたもので構成されています。\nPod のリソース定義を表示するには以下を実行します。\nkubectl get pod -l app=blog -o yaml ここでは、Replicaset のspec.template のフィールドがPod のリソース定義の作成に使われています。\nReplicaset とPod の両方で、多くのフィールドが追加されていることがわかります。これは、元のDeployment では指定されていなかった値のデフォルトが記入されているためです。また、リソース定義には、リソースのステータスを追跡するためのフィールドも含まれています。\n継承されたデフォルトの場合、リソースの種類によって異なりますが、グローバル構成やネームスペース構成から一部が継承されている場合もあります。例えば、CPUとメモリのリソース制限は、作業しているネームスペースで設定された制限を継承しています。\nいずれにしても、これらのデフォルト値が正しくないことが判明し、それらを変更する必要がある場合、または追加の設定を追加する必要がある場合は、その変更をDeployment で行う必要があります。Replicaset やPod を自分で直接編集してはいけません。代わりにDeployment を更新してください。Replicaset とPod のインスタンスは、それに対応して更新されます。\nKubernetes の世界ではマニフェストがすべてです。例えばReplicaset のマニフェストを直接編集すると、それを管理するDeployment との整合性にズレが生じるため、整合性を取るようDeployment のマニフェストに従うように再構成されます。すなわち、Replicaset を編集したところで、自動的に編集前の状態に戻ります。  アプリケーションを削除する際には、先ほどフロントエンドのWebアプリケーションで行ったように、Replicaset もPod も明示的に削除する必要はありません。これは、Pod は作成元のReplicaset が所有するものとしてマークアップされ、Replicaset はDeployment が所有するものとしてマークされるためです。Deoloyment を削除すると、Replicaset と、そこから作成されたPod は自動的に削除されます。\nスケールアウト #  Pod をスケールアウトしてみましょう。先ほど説明した通り、Pod やReplicaset を編集するのではなく、Deployment のマニフェスト中のspec.replicas の値を変更する必要があります。今回は、レプリカの数を3 に増やすために、Deployment のマニフェストを更新し、再びApply してみましょう。\nsed -i -e \u0026#34;s/replicas: 2/replicas: 3/\u0026#34; ~/frontend/deployment.yaml kubectl apply -f ~/frontend/deployment.yaml kubectl get pods -l app=blog\r コマンドをすぐに実行した場合、「Pending（保留）」または「ContainerCreating（コンテナ作成中）」状態のPod が表示されることがあります。これは新しいPod が起動しているところです。Running 状態のPodが3つ表示されるまで、kubectl get podsを実行し続けます。\nこのように、非常に簡単にPod をスケールアウトさせることができました。仮想マシンの場合、通常このように即座にスケールアウトすることはできません。コンテナを利用する1 つのメリットとして、このように拡張性に非常に優れることが挙げられます。\nPod とコンテナ #  Pod がアプリケーションのインスタンスを表すことはすでに述べたとおりです。\nより正確に言うと、Pod は、実行中のコンテナのグループを表す抽象的なもので、Pod はコンテナの管理およびスケーリングをするための単なるグルーピングにすぎません。\nほとんどの場合、Pod は1つのコンテナのみで構成されます。1つのPod で複数のコンテナを実行するユースケースもありますが、一般的には例外的なケースです。\n今回のハンズオンで使用するサンプルアプリケーションを見ると、2つの別々のDeployment があります。1つはフロントエンドのWeb サーバー用、もう1つはデータベース用です。\nkubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE\rblog 2/2 2 2 64s\rblog-db 1/1 1 1 34s\r このようにDeployment を分けることで、フロントエンドのWebアプリケーションをデータベースとは別に複数のインスタンスにスケールアップすることができます。両方のコンポーネントが1 つのDeployment の一部として作成され、Pod の別々のコンテナで実行されていた場合、アプリケーションを複数のインスタンスにスケールアップすることはできません。これは、データベースはデータと紐づくため（＝ステートフル）、データの整合性などを気にする必要があり、Web サーバーのようなステートレスアプリケーションのようにレプリカ数を簡単に増やすことはできないからです。\nその他のリソース #  本ハンズオンでは紹介できませんが、Kubernetes には他にも沢山のリソースがあります。また、自分でリソースを作ることもできます。詳細はKubernetes のドキュメントを参照してください。\n参考 : https://kubernetes.io/docs/concepts/\r\n演習 #  Deployment で管理されるPod (Deployment \u0026gt; Replicaset \u0026gt; Pod) を手動で削除した場合、何が起こると考えられますか？\n解答 Deployment のマニフェストの中のReplicaset のspec でPod のレプリカ数を定義しているため、Replicaset のマニフェストと整合性を取るよう、Pod が再作成されます。確かめてみましょう。\nまずは今稼働しているPod を表示してみましょう。\nkubectl get pods -l app=blog NAME READY STATUS RESTARTS AGE\rblog-65c8484545-7c8qk 1/1 Running 0 20m\rblog-65c8484545-qbvvp 1/1 Running 0 20m\r 次に、Pod を手動で削除します。Pod 名は環境によって異なるため、先ほど表示されたもののどちらか一方を使用してください。\nkubectl delete pods blog-65c8484545-7c8qk すると、以下のように表示されるはずです。\npod \u0026quot;blog-65c8484545-7c8qk\u0026quot; deleted\r しかしながら、再度稼働中のPod を表示してみると、Pod の数に変化がありません。\nNAME READY STATUS RESTARTS AGE\rblog-65c8484545-br9mf 1/1 Running 0 8s\rblog-65c8484545-qbvvp 1/1 Running 0 21m\r これは、実際にはPod が削除された後、自動的にPod が再作成されているためです。その証拠に、先ほど削除したPod 名(この例ではblog-65c8484545-7c8qk) は存在せず、作成されたばかりの（この例ではAGE=8s）、別名のPod が表示されています。\n  "},{"id":7,"href":"/k8s-workshop/docs/container/image/","title":"イメージ","section":"コンテナハンズオン","content":"イメージとは #  コンテナイメージから実行中のコンテナを作成しました。使用したコンテナイメージは、イメージレジストリから取得したものです。一般的に使用されているソフトウェアアプリケーション用のコンテナイメージは数多くありますが、自分のアプリケーション用にコンテナイメージを作成することの方が多いでしょう。\nコンテナイメージとは、アプリケーションを配布するためのパッケージメカニズムであり、アプリケーションの実行に必要なアプリケーションソフトウェア、オペレーティングシステムファイル、ライブラリ、その他のソフトウェアを含んでいると説明しました。\nその意味では、コンテナイメージは、ファイルシステムを構成するために解凍されるtarballやzipファイルのようなものだと言えます。しかし、それよりも少し複雑です。\nコンテナイメージは、すべての必要なファイルを含む単一のパッケージではなく、パッケージの集合体であり、それぞれがコンテナイメージの1つのレイヤーのファイルを含んでいます。\nコンテナイメージのレイヤー\n各コンテナイメージは、まずベースレイヤーから始まります。ベースレイヤーには、通常、ベースとなるOSファイル、アプリケーション、ライブラリがすべて含まれています。\nその上にさらにレイヤーを追加していきます。各レイヤーでは、ファイルを追加したり、既存のファイルを変更したり、ファイルを削除したりします。\n既存のファイルを修正したり削除したりする場合、変更されるのは下位レイヤーのオリジナルファイルではありません。修正の場合は、変更を加えたファイルの新しいコピーが新しいレイヤーに存在し、下のレイヤーのオリジナルはそのまま存在します。ファイルの削除の場合は、そのレイヤーでファイルが削除されたことがレイヤーのメタデータに記録され、オリジナルは下のレイヤーに残っています。\nこのように変更や削除が行われるのは、各レイヤーが不変であるためです。変更を加えるには、新しいレイヤーを作成するしかありません。\nコンテナイメージを使用してコンテナを作成する場合は、コンテナイメージの各レイヤーを重ね合わせてレイヤーを合成して表示する特殊なファイルシステムが使用されます。\n読み取り専用ファイルシステム\nこの最終的なコンポジットビューは、それ自体が読み取り専用である。コンテナ内のファイルに加えられた変更は、コンテナの寿命まで存在する別のレイヤに存在することになる。\nコンテナのイメージフォーマットの実際の仕様は、OCI Image Format Specification で定義されています。また、コンテナ内でアプリケーションを実行するために、イメージをどのようにアンパックし、解釈し、使用するかは、OCI Runtime Specificationで定義されています。どちらの仕様も、Linux FoundationがスポンサーとなっているOpen Container Initiative のガバナンスの下で管理されています。\nイメージのビルド #  コンテナイメージを構築するには、主に3つの方法があります。\n  既存のイメージを使ってコンテナを起動し、コンテナに変更を加え、その結果を新しいコンテナイメージとして保存することで、インタラクティブにイメージを構築する方法。\n  入力ファイルに記述されたスクリプトを使って、バッチプロセスでコンテナイメージを作成する。典型的な例としては、Dockerfileを使用してコンテナイメージを作成することが挙げられる。\n  tarballからファイルシステムのコピーをインポートしてコンテナイメージを作成する。\n  このワークショップでは、典型的な手法である2 つめのDockerfile を用いた方法を見ていきます。\nDockerfile #  ~/greeting-v1 に移動します。\ncd ~/exercises/greeting-v1 Dockerfileは、新しいコンテナイメージを作成するベースイメージの詳細と、それを作成するための手順を定義しています。Dockerfile の内容を表示します。\ncat Dockerfile FROMbusybox:latestCOPY hello goodbye /CMD [ \u0026#34;/hello\u0026#34; ]DockerfileのFROM命令は、ベースイメージの名前を指定します。\nCOPY命令は、ローカルディレクトリからイメージにファイルをコピーするために使用されます。\nCMD命令は、コンテナイメージが明示的なコマンドを指定せずに実行された場合に実行されるコマンドを設定するために使用します。\nDockerfileの命令を使ってコンテナイメージを構築するには、次のように実行します。\ndocker build -t greeting . -t でイメージの名前を指定し、\u0026quot;.\u0026quot; はDockerfile のパスを指定しています。\nコンテナイメージのレイヤーを見るには、次のように実行します。\ndocker history greeting 以下のような出力が得られるはずです。\nIMAGE CREATED CREATED BY SIZE COMMENT 0ac1216f0e3f 4 seconds ago /bin/sh -c #(nop) CMD [\u0026#34;/hello\u0026#34;] 0B aeea9801fb6a 4 seconds ago /bin/sh -c #(nop) COPY multi:03e82c91fe5fcae… 50B be5888e67be6 5 days ago /bin/sh -c #(nop) CMD [\u0026#34;sh\u0026#34;] 0B \u0026lt;missing\u0026gt; 5 days ago /bin/sh -c #(nop) ADD file:09a89925137e1b768… 1.22MB コンテナイメージの中に、DockerfileからのCOPYとCMDの文のためのレイヤーが作成されていることがわかります。\nコンテナイメージを実行するには、次のように実行します。\ndocker run --rm greeting あるいは、別のコマンドを実行するには、次のようにします。\ndocker run --rm greeting /goodbye Dockerfileで使用できる命令の完全なリストについては、Dockerfileリファレンスをご覧ください。\nイメージの共有 #  独自のカスタムコンテナイメージを作成した後、それを別のホストシステムで実行する必要がある場合には、そのイメージを配布する方法が必要になります。\nコンテナイメージを配布する一般的な方法は、イメージレジストリにプッシュすることです。イメージレジストリにプッシュされたコンテナイメージは、他のホストにプルダウンして実行することができます。このためには、Docker Hub や Quay.io などのパブリックなイメージレジストリを使用するか、独自のプライベートなイメージレジストリを使用することができます。\nイメージをイメージレジストリにプッシュするには、まずそのイメージレジストリーにログインする必要があります。\nこのワークショップの環境では、あなたはすでにログインしている自分のプライベートイメージレジストリを持っています。もし自分でやるのであれば、docker loginコマンドを使ってイメージレジストリの場所を指定します。すると、ログイン情報の入力を求められます。\n次に、コンテナイメージにイメージレジストリの名前を組み込んだ名前をタグ付けする必要があります。\nこの時点でのイメージの名前はgreetingなので、イメージレジストリの名前を含む名前をタグ付けするには、次のように実行する必要があります。\nNS=$(kubectl config view -o jsonpath=\u0026#39;{.contexts[].context.namespace}\u0026#39;) 上記コマンドはハンズオンのセッションによって異なるレジストリの名前の一部を取得しています。  docker tag greeting:latest ${NS}-registry.tdc-priv-prod-1e19974.tanzu-labs.esp.vmware.com/greeting:latest イメージをイメージレジストリにプッシュするには、次のように実行します。\ndocker push ${NS}-registry.tdc-priv-prod-1e19974.tanzu-labs.esp.vmware.com/greeting:latest イメージレジストリへの適切なアクセス権を持つ人は、次のように実行して、イメージを別のホストでプルすることができます。\ndocker pull ${NS}-registry.tdc-priv-prod-1e19974.tanzu-labs.esp.vmware.com/greeting:latest "},{"id":8,"href":"/k8s-workshop/docs/kubernetes/troubleshooting/","title":"トラブルシューティング","section":"Kubernetes ハンズオン","content":"コンテナのロギング #  アプリケーションの各インスタンスは、それぞれのポッドの中で実行されます。\nすでに見たように、フロントエンドWeb サーバーのポッドをリストアップするには、次のようにします。\nkubectl get pods -l app=blog -o name アプリケーションの特定のインスタンスのログ出力にアクセスするには、kubectl logsコマンドでポッドの名前を使用できます。今回は複数のポッドがあるので、そのうちの1つの名前だけを取得する必要があります。\nPOD=`kubectl get pod -l app=blog -o template --template \u0026#39;{{range .items}}{{.metadata.name}}{{\u0026#34;\\n\u0026#34;}}{{end}}\u0026#39;. | head -1` \u0026amp;\u0026amp; echo $POD 次にkubectl logsを実行します。\nkubectl logs $POD ポッド内に複数のコンテナがある場合は、-c または \u0026ndash;container オプションを使用してコンテナに名前を付ける必要があります。 また、実行中のアプリケーションの出力を追跡したい場合は、-fまたは\u0026ndash;followオプションを使用できます。  コンテナへのアクセス #  コンテナにアクセスしてコマンドを実行するには、kubectl execを使用します。ロギングと同様に、アクセスしたい特定のポッドを指定する必要があり、ポッド内で複数のコンテナが動作している場合は、-cまたは\u0026ndash;containerオプションを使用してどのコンテナかを指定します。\nkubectl exec $POD env 対話型のターミナルセッションを実行したい場合は、docker と同様、-iまたは\u0026ndash;stdinオプションと、-tまたは\u0026ndash;ttyオプションを使用する必要があります。\nkubectl exec -it $POD -- bash 一通り確認したら、対話型シェルを終了してください。\nexit "},{"id":9,"href":"/k8s-workshop/docs/container/summary/","title":"まとめ","section":"コンテナハンズオン","content":"まとめ #  お疲れ様でした。\n"},{"id":10,"href":"/k8s-workshop/docs/kubernetes/network/","title":"ネットワーク","section":"Kubernetes ハンズオン","content":"名前空間 #  ネットワークの前に簡単にNamespace (名前空間) に関して説明します。名前空間はKubernetes におけるリソースを適切に分離する仕組みのことです。例えば、1つのKubernetes クラスタを複数で利用する際に、名前空間を分けない場合はアプリケーションの名前が被ってはいけませんが、名前空間を分けることで、このような重複を気にする必要がなくなります。他にも、名前空間の間の通信を制御したり、機能を制限したりと、Kubernetes におけるマルチテナントの提供形態の1 つと言い換えることもできます。\n例えば、これまでのハンズオンの中でkubectl を使った操作の時には名前空間を意識していませんでしたが、実際はハンズオンのセッションごとに個別に割り当てられた名前空間の中で作業をしていました。\n名前空間を指定しない場合：\nkubectl get pod 名前空間を指定する場合：\nkubectl get pod -n ${NS} 通常、何も設定しない場合のデフォルトの名前空間の名前は\u0026quot;default\u0026quot;となります。  このハンズオンの仕組みとして、ユーザーのセッションごとに個別に名前空間が割り当てられ、みなさんはその名前空間の中で作業しています。\nkubectl get namespaces NAME STATUS AGE\rdefault Active 68d\reduk8s Active 68d\reduk8s-ingress Active 68d\reduk8s-labs-ui Active 68d\reduk8s-labs-w01 Active 68d\reduk8s-labs-w01-s283 Active 172m\reduk8s-labs-w01-s284 Active 109m\reduk8s-labs-w01-s285 Active 46m\r...\r ただし、他のユーザーに割り当てられた名前空間やKubernetes が内部で使用している名前空間へのアクセスは制限されています。名前空間ごとに適切にアクセスコントロールができていると言えますね。\nkubectl get pod -n kube-system Error from server (Forbidden): pods is forbidden: User \u0026quot;system:serviceaccount:eduk8s-labs-w01:eduk8s-labs-w01-s283\u0026quot; cannot list resource \u0026quot;pods\u0026quot; in API group \u0026quot;\u0026quot; in the namespace \u0026quot;kube-system\u0026quot;\r Kubernetes のネットワークの基本 #  Kubernetes ではPod 単位でIP アドレスがアサインされます。各ポッドに割り当てられているIPアドレスは、次のように実行することで確認できます。\nkubectl get pods -l app=blog -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\rblog-65c8484545-br9mf 1/1 Running 0 28m 192.168.12.67 ip-10-0-3-148.us-east-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;\rblog-65c8484545-qbvvp 1/1 Running 0 49m 192.168.12.111 ip-10-0-3-148.us-east-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;\r これらのIPアドレスは、Kubernetesクラスタ内でのみアクセス可能です。直接、外部からアクセスすることはできません。\nPod は複数のコンテナを含む場合は、そのコンテナ間の通信はlocalhost で実行され、待ち受けるポートは重複してはいけません。例えば、1つのPod の中に80番ポートで待ち受けるnginx コンテナを2つ以上含めることはできません。\nPod 間の通信は、CNI (Container Network Interface) プラグインが担います。つまり、CNI は、このようにPod によしなにIP アドレスを振って、Pod 同士が通信できるよう取り計らう役割を持っています。Kubernetes クラスタを作成する場合CNI プラグインのインストールが必要なため、今回のハンズオン環境では確認することはできませんが、この環境にも当然CNI はインストールされています。CNI の例としては、Calico\r やAntrea\r が挙げられます。\nService リソース #  次に、Pod と外部との通信ですが、これはKubernetes のリソースであるService リソースを介して行われます。先ほど説明した通り、Pod のIPアドレスは、Kubernetesクラスタ内でのみアクセス可能ですので、直接外部ネットワークからアクセスすることは基本的にできません。\n加えて、Pod は短命です。Replicaset の役割はPod をレプリカの数だけ稼働させることであり、停止したPod を再起動させるわけではなく、再作成します。この場合はPod の名前やIPアドレスも変更されます。すなわち、通信先のコンポーネントのIP アドレスは変わるものとしてアプリケーションを設計しなければなりません。\nアプリケーションに安定したIPアドレスとホスト名を割り当て、かつ外部との接続を実現するために、Kubernetes にはService リソースと呼ばれるリソースがあります。 Service という名前がややこしいですが、Pod やDeployment などと同様、Kubernetes にService という名前のリソースがあります。  さっそくService リソースのマニフェストを確認します。\ncat ~/frontend/service.yaml apiVersion: v1\rkind: Service\rmetadata:\rname: blog\rlabels:\rapp: blog\rspec:\rtype: ClusterIP\rselector:\rapp: blog\rports:\r- name: 8080-tcp\rport: 8080\rprotocol: TCP\rtargetPort: 8080\r これをkubectl apply すると、blog という名前のService が作成されたことになります。このマニフェストは「app:blog というラベルが付いたアプリケーションのためにポート8080 を公開し、Pod が待ち受けているポート8080 にマッピングします」ということを意味しています。\n既にこのService は作成されているため、Service の詳細を確認してみましょう。\nkubectl get service --selector app=blog -o wide これにより、以下のような出力が表示されます。\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR\rblog ClusterIP 10.108.113.113 \u0026lt;none\u0026gt; 8080/TCP 28m app=blog\r SELECTOR に注目しましょう。これはマニフェスト中のspec.selector の値です。\nselector:\rapp: blog\r これは、どのPod をService のエンドポイントとして登録するかを定義していて、これはラベルによって制御されます。すなわち下記のコマンドの実行で得られるPod をService のエンドポイントとして登録し、Service のIP アドレスでアクセスできるようにします。\nkubectl get pods -l app=blog -o name ラベル管理を適切にしないと、意図しないPod がService のバックエンドに配置される場合があります。  なお、サービスに対して登録されているポッドのIPアドレスは、次のように実行することで確認できます。\nkubectl get endpoints blog Service のIPアドレスはそのService が存続する限り変更されることはありませんが、それでもそのIP は使用すべきではありません。代わりに、Service に対応するホスト名を使用するべきです。ホスト名は自動的にKubernetesクラスタの内部DNSに登録され、クラスタ内のどのアプリケーションでも使用できます。ホスト名の命名規則については下記ドキュメントを参照してください。\n参考：https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/\r\n注意点として、今回作成したService に対して、Kubernetesクラスタの外から直接そのIP アドレスやホスト名にアクセスすることはできません。これは、今回作成したService がClusterIP と呼ばれるタイプであり、Pod のIP アドレスと同様、ClusterIP はクラスタ内で使用される安定したIP アドレスやホスト名の提供を目的としているためです。\n補足 実はこの環境ではmy-svc.my-namespace.svc.cluster-domain.example （もしくはIP アドレス）のような形でターミナルからアクセスできます。本環境の場合は以下のようになります。\ncurl http://blog.${NS}.svc.cluster.local:8080 ただし、ターミナルの外、すなわちブラウザの別タブなどからアクセスすることはできません。これは、今回のハンズオン環境で提供されるターミナルの実体がまさにKubernetes のPod であり、そこからcurl を実行するということは、クラスタ内での通信に他ならないからです。\n  Ingress によるService の公開 #  Service をKubernetes クラスタの外からアクセスできるように公開するためには、Ingressリソースオブジェクトを作成する必要があります。\n今回使用するIngressリソースオブジェクトの定義を見るには、runを使用します。\ncat ~/frontend/ingress.yaml apiVersion: extensions/v1beta1\rkind: Ingress\rmetadata:\rname: blog\rlabels:\rapp: blog\rspec:\rrules:\r- host: blog-eduk8s-labs-w01-s284.tdc-reg-prod-d66138e.tanzu-labs.esp.vmware.com\rhttp:\rpaths:\r- path: \u0026quot;/\u0026quot;\rbackend:\rserviceName: blog\rservicePort: 8080\r この例では、blog-eduk8s-lab-w01-s284.tdc-reg-prod-d66138e.tanzu-lab.esp.vmware.comというホスト名で受信したHTTPリクエストは、blogという名前を持つService（つまりアプリケーション）に向けられるべきだというルールになっています。\n外部のユーザーがWebブラウザからホスト名にアクセスする場合、HTTPトラフィックに標準のポート80を使用しますが、ルーターはそのトラフィックをサービスのポート8080に渡します。\nIngress も既に作成しているので、以下のコマンドで確認することができます。\nkubectl get ingress -l app=blog 払い出されたURL を使ってWebブラウザからフロントエンドのWebアプリケーションにアクセスできます。ターミナルではなく、ブラウザの別タブから払い出されたURL にアクセスしてください。\nNS=$(kubectl config view -o jsonpath=\u0026#39;{.contexts[].context.namespace}\u0026#39;) echo $NS http://blog-${NS}.tdc-reg-prod-d66138e.tanzu-labs.esp.vmware.com 1つ目のコマンドはこの環境で払い出されるURL 名の一部（名前空間）を取得しています。URL 中の${NS} は取得した名前空間で置き換えてください。例えば下記のようになります。\nhttp://blog-eduk8s-labs-w01-s287.tdc-reg-prod-d66138e.tanzu-labs.esp.vmware.com\r\n この時点では 500 Internal Server Error が表示されることに注意してください。  このリンクをクリックして、フロントエンドのWebアプリケーションにアクセスします。利用できないと表示された場合は、利用できるようになるまでページを更新してください。これは、Ingress ルーティングの再設定に時間がかかるためです。\nこれは、このホストのトラフィックをKubernetesクラスタのルータに向けるために、外部のドメインネームサーバ（DNS）でワイルドカードCNAMEがすでに事前に設定されているために機能することに注意してください。これが自分のKubernetesクラスタであれば、使用したいホストのDNSに適切なCNAMEを設定する必要があります。\n"},{"id":11,"href":"/k8s-workshop/docs/kubernetes/storage/","title":"ストレージとデータベース","section":"Kubernetes ハンズオン","content":"ストレージの基本 #  繰り返しになりますが、Pod は短命です。Pod は簡単に削除されるため、データを残したい場合は何かしらの形で外部に保存する仕組みが必要です。その1 つがPersistent Volume （PV）になります。\nPV はその名の通り永続ストレージであり、PV の中にデータを保存することができます。PV をPod に割り当てるにはいくつか方法がありますが、代表的なものとしてPersistent Volume Claim (PVC) を使う方法があります。PVC はPV を要求するために使われるリソースであり、そのマニフェストの中には例えば要求するストレージのサイズなどが定義されます。Pod がデータを保存するためにPV を使いたい場合は、直接PV をアタッチするのではなく、PVC をアタッチします。\nPVC のマニフェストを見てみましょう。\ncat ~/database/persistentvolumeclaim.yaml apiVersion: v1\rkind: PersistentVolumeClaim\rmetadata:\rname: blog-media\rlabels:\rapp: blog\rspec:\raccessModes:\r- ReadWriteOnce\rresources:\rrequests:\rstorage: 1Gi\r ここでは、ストレージのサイズは少なくとも1Giで、アクセスモードはReadWriteOnce である必要があります。アクセスモードとは、払い出すPV がどのようにRead/Write されうるかを示しており、以下の4 つがあります。\n ReadWriteOnce(RWO) - 単一のノードからRead/Write 可能としてボリュームをマウントします。 ReadOnlyMany (ROX) - 複数のノードによって読み取り専用としてボリュームをマウントします。 ReadWriteMany (RWX) - 複数のノードによってRead/Write 可能としてボリュームをマウントします。 ReadWriteOncePod (RWOP) - 単一のPod からRead/Write 可能としてボリュームをマウントします。  なお、使用するKubernetes クラスタによってはRWX が使えないなどの制約があります。\nRWO, ROX, RWX のアクセス元はいずれも\u0026quot;ノード\u0026quot;であることに注意してください。すなわち、RWO を選択したとしても、複数のPod が同一ノード上で稼働していれば、そのPV にはアクセスが可能です。  既に作成したデータベースのマニフェストを見てみましょう。\ncat ~/database/deployment.yaml apiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: blog-db\rlabels:\rapp: blog-db\rspec:\r...\rtemplate:\r...\rspec:\rcontainers:\r...\rvolumeMounts:\r- name: data\rmountPath: \u0026quot;/var/lib/pgsql/data\u0026quot;\rvolumes:\r- name: data\rpersistentVolumeClaim:\rclaimName: blog-database\r spec.template.spec.volumes に使用するPVC のリソースオブジェクト名が記載され、その請求されるPV がdata と名付けられ、さらにそれがspec.template.spec.containers[*].volumeMounts にてコンテナのパス/var/lib/pgsql/data にマウントされていることが分かります。 フロントのWeb サーバーにもPV がマウントされていますが、これはブログの記事ではなく画像を保存するためのものです。  補足 今回使用しているフロントエンドのWebアプリケーションでは、複数のノードにまたがる複数のPod から画像を保存するPV にアクセスさせることを可能にしたいため、厳密にいえばReadWriteMany のPV を使うべきですが、環境に寄ってはReadWriteMany が使えない場合があるため、特定のノードに固定してデプロイされるようにしています(マニフェストではaffinity として設定されています)。一方、データベースは1 つのインスタンスしか持たないので、アクセスモードがReadWriteOnceのストレージで十分です。   データベースとの接続 #  フロントエンドのWebアプリケーションが動作しており、公共のインターネットからアクセスできます。この時点では、ファイルベースのSQLiteデータベースを使用しています。このデータベースは各インスタンスに対してローカルであり、すべてのインスタンス間で共有されていないため（スケールアップしたアプリケーションには不向き）、ポッドが再起動するたびにデータへの変更が失われます。\nデータの永続性を確保し、アプリケーションのすべてのインスタンスで同じデータベースを使用するために、フロントエンドのWebアプリケーションでは、すでに稼働している別のPostgresqlデータベースを使用するように設定します。\nデータベースのリソースを表示するには、以下を実行します。\nkubectl get deployment,service,pvc,secret -l app=blog-db -o name\ndeployment.apps/blog-db\rservice/blog-db\rpersistentvolumeclaim/blog-database\rsecret/blog-credentials\r これで、デプロイメントとサービスの目的が理解できたはずです。persistentvolumeclaim は、データベースが使用する永続的なストレージを要求するために使用されます。secret は、データベースの認証情報を保持するために使用されます。\nデータベースをフロントエンドのウェブアプリケーションにリンクさせるためには、フロントエンドのウェブアプリケーションにデータベースのホスト名とログイン認証情報を伝える必要があります。そのためには、フロントエンド Web アプリケーションの配置に環境変数の設定を追加する必要があります。\nフロントエンドWebアプリケーションにどのような環境変数がすでに設定されているかは、次のように実行すればわかります。\nkubectl set env deployment/blog \u0026ndash;list これで表示されるはずです。\nデプロイメントブログ、コンテナブログ #  BLOG_SITE_NAME=EduK8Sブログ フロントエンドWebアプリケーションの実装方法では、別のデータベースのために以下の環境変数を期待しています。\nDATABASE_HOST - データベースのホスト名です。 DATABASE_USER - データベースにログインするユーザーです。 DATABASE_PASSWORD - データベースにログインするユーザーのパスワードです。 DATABASE_NAME - データベースの名前です。 環境変数を設定するために、kubectlにはkubectl set envというコマンドが用意されています。本番の設定を更新するのではなく、ローカルに設定を保持するのですが、その設定に必要な変更を行うために使用します。\nデータベースホストについては、ホスト名はデータベースサービスオブジェクトの名前、つまりblog-dbとなります。\nこのセットでデプロイメント構成がどうなるかを確認するには、次のように実行します。\nkubectl set env deployment/blog DATABASE_HOST=blog-db \u0026ndash;dry-run -o yaml 出力結果を見ると、既存のBLOG_SITE_NAME環境変数に加えて、DATABASE_HOST環境変数が追加されていることがわかります。これは、spec.template.spec.container.envの設定の下にあります。\n"},{"id":12,"href":"/k8s-workshop/docs/kubernetes/summary/","title":"まとめ","section":"Kubernetes ハンズオン","content":"今回のハンズオンでは、Kubernetes を実際に触ってみて、フロントエンドのWebアプリケーションからなるアプリケーションをデプロイし、バックエンドのPostrgreSQLデータベースを使ってブログサイトを実装しました。\nKubernetesの一般的な情報については、以下を参照してください。\nhttps://kubernetes.io/\r\n自分のPC でKubernetesを試してみたい方は、ぜひTanzu Community Edition を使ってみてください。\nhttps://tanzucommunityedition.io/\r\n"}]